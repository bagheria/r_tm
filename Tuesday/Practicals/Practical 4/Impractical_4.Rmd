---
title: "Impractical 4: Sentiment analysis"
author: "Ayoub Bagheri"
date: "Introduction to Text Mining with R"
mainfont: Arial
fontsize: 12pt
urlcolor: blue
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 1
    toc_float: true
    df_print: paged
    theme: paper
    pandoc_args: --output=Practical_4.html
---

# Introduction

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

Welcome to the fourth practical of the course "Introduction to Text Mining with R". In this practical, we will analyze sentiments in a text data set, first by using dictionaries and then we will classify sentiment in text reviews comparing a dictionary-based method and a neural network model.

In this practical we are going to use the following packages:

```{r load_packages, message = FALSE, warning = FALSE}
library(tm)
library(tidytext)
library(dplyr)
library(ggplot2)
library(caret)
library(rpart)
library(rpart.plot)
```

---

# Read data

---

1. **In today's practical, we want to use Taylor Swift song lyrics data from all her albums. Read the "taylor_swift.csv" dataset from the data folder.**

---

```{r 1, message = FALSE, warning = FALSE, include = TRUE}


```

---

2. **First we must preprocess the corpus. Create a document-term matrix from the `lyrics` column of the `ts` data frame. Complete the following preprocessing steps:**
- convert to lower
- remove stop words
- remove numbers
- remove punctuation.

---


```{r 2, message = FALSE, warning = FALSE, include = TRUE}


```

---

3. **Inspect the dtm object and convert it to a dataframe.**

---

```{r 3, message = FALSE, warning = FALSE, include = TRUE}


```


---

# Sentiment dictionaries

---

4. **We're going to use sentiment dictionaries from the `tidytext` package. Using the `get_sentiments` function, load the "bing" and "afinn" dictionaries and store them in two objects called `bing_sentiments` and `afinn_sentiments`. You might need to install the "textdata" package.**

The tidytext package contains 4 general purpose lexicons in the sentiments dataset.

afinn - listing of English words rated for valence between -5 and +5

bing - listing of positive and negative sentiment

nrc - list of English words and their associations with 8 emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and 2 sentiments (negative and positive); binary

loughran - list of sentiment words for accounting and finance by category (Negative, Positive, Uncertainty, Litigious, Strong Modal, Weak Modal, Constraining)

---

```{r 4, message = FALSE, warning = FALSE, include = TRUE}


```

---

5. **The afinn_sentiments has the rating for valence between -5 and +5, while the bing_sentiments contains listing of positive and negative sentiment. Add a column to `bing_sentiments` called `score`. This column should hold a "1" for positive words and "-1" for negative words.**

---

```{r 5, message = FALSE, warning = FALSE, include = TRUE}


```

---

# Sentiment score for each lyric

---

6. **Create a dataframe that holds all the words in the dtm object along with their sentiment score.**

---

```{r 6, message = FALSE, warning = FALSE, include = TRUE}


```

---

7. **To calculate a score for each lyric, multiply your dtm object by the scoring dataframe.**

---

```{r 7, message = FALSE, warning = FALSE, include = TRUE}


```

---

8. **Add the calculated scores for each lyric to the original `taylor_swift_lyrics` dataframe.**

---

```{r 8, message = FALSE, warning = FALSE, include = TRUE}


```

---

9. **Plot the bing sentiment scores for each lyric.**

---

```{r 9, message = FALSE, warning = FALSE, include = TRUE}


```

---

10. **Using the code you wrote above, below we create a function that gets 1) a vector of texts, and 2) a sentiment dictionary (i.e. a dataframe with words and scores), and returns a vector of sentiment scores for each text. Use this function to repeat your analysis with the `afinn` sentiment dictionary.**

---

```{r 10, message = FALSE, warning = FALSE, include = TRUE}


```

```{r 10+1, message = FALSE, warning = FALSE, include = TRUE}


```

```{r 10+2, message = FALSE, warning = FALSE, include = TRUE}


```

---

11. **Compare the bing and afinn dictionaries by finding out which the most and least positive Taylor Swift album is. You can also plot the sentiments for albums.**

---

```{r 11, message = FALSE, warning = FALSE, include = TRUE}


```

---

# Sentiment analysis of product reviews
In this part of the practical, we will do some sentiment analysis on computer product reviews. For this purpose, we will use our processed data set from the first practical: the computer_531 dataset.

---

12. **Load the `computer_531` dataframe you created at the very end of the first practical**

---

```{r 12, message = FALSE, warning = FALSE, include = TRUE}

```

---

13. **Apply the `sentiment_score` function on the reviews in the dataframe with both bing and afinn dictionaries.**

---

```{r 13, message = FALSE, warning = FALSE, include = TRUE}


```

---

14. **Create a confusion matrix, and calculate Accuracy, precision, recall and F1 measures for the output of the bing dictionary.**

---

```{r 14, message = FALSE, warning = FALSE, include = TRUE}

```

---

15. **Create a confusion matrix, and calculate Accuracy, precision, recall and F1 measures for the output of the afinn dictionary.**

---

```{r 15, message = FALSE, warning = FALSE, include = TRUE}

```

---

16. **From the `rpart` package, we want to build a tree on this dataset to predict sentiments. For this purpose, first prepare your data by doing preprocessing on reviews, converting to dtm and creating training and test sets.**

---

```{r 16, message = FALSE, warning = FALSE, include = TRUE}


```

---

17. **Now build a tree with the default setting of the rpart function, and visualize the tree.**

---

```{r 17, message = FALSE, warning = FALSE, include = TRUE}


```

---

18. **Check the performance of the tree on your training set.**

---

```{r 18, message = FALSE, warning = FALSE, include = TRUE}


```

---

19. **Check the performance of the tree on the test set, and compare it with the training performance.**

---

```{r 19, message = FALSE, warning = FALSE, include = TRUE}


```

Here you found that while decision trees could outperform a simple dictionary-based method, they are not very good with high dimensional data such as text. If you have some time left try a Random Forest, naive Bayes, or SVM to compare the performance. They will perform better, but you will lose interpretability!

---

# Summary

---

In this practical, we learned about:

- Sentiment analysis
- Dictionary-based methods
- Available sentiment dictionaries
- Learning sentiments
- Decision trees

---

End of Practical

---